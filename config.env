# LLM Configuration
LLM_PROVIDER=ollama  # Options: ollama, openai
OPENAI_API_KEY=your_openai_api_key_here
OLLAMA_MODEL=llama2  # Default model for Ollama

# Embedding Configuration
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384

# Database Configuration
CHROMA_PERSIST_DIRECTORY=./data/chroma_index
SQLITE_DB_PATH=./data/knowledge_search.db

# Document Processing
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_CHUNKS_PER_QUERY=10

# Retrieval Configuration
BM25_K1=1.2
BM25_B=0.75
HYBRID_ALPHA=0.7  # Weight for semantic vs BM25 (0.7 = 70% semantic, 30% BM25)

# Context Optimization
SIMILARITY_THRESHOLD=0.9
MAX_CONTEXT_TOKENS=4000

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=
CACHE_ENABLED=true
CACHE_TTL=3600  # 1 hour

# Load Balancing
WORKERS=4
